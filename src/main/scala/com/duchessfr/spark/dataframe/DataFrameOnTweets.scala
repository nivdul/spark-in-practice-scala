package com.duchessfr.spark.dataframe

import org.apache.spark._
import org.apache.spark.sql._

/**
 *  The Spark SQL and DataFrame documentation is available on:
 *  https://spark.apache.org/docs/1.4.0/sql-programming-guide.html
 *
 *  A DataFrame is a distributed collection of data organized into named columns.
 *  The entry point before to use the DataFrame is the SQLContext class (from Spark SQL).
 *  With a SQLContext, you can create DataFrames from:
 *  - an existing RDD
 *  - a Hive table
 *  - data sources...
 *
 *  In the exercise we will create a dataframe with the content of a JSON file.
 *
 *  We want to:
 *  - print the dataframe
 *  - print the schema of the dataframe
 *  - find people who are located in Paris
 *  - find the user who tweets the more
 * 
 *  And just to recap we use a dataset with 8198 tweets,where a tweet looks like that:
 *
 *  {"id":"572692378957430785",
 *    "user":"Srkian_nishu :)",
 *    "text":"@always_nidhi @YouTube no i dnt understand bt i loved of this mve is rocking",
 *    "place":"Orissa",
 *    "country":"India"}
 * 
 *  Use the DataFrameOnTweetsSpec to implement the code.
 */
object DataFrameOnTweets {


  val pathToFile = "data/reduced-tweets.json"

  /**
   *  Here the method to create the contexts (Spark SQL) and
   *  then create the dataframe.
   *
   *  Run the test to see how looks the dataframe!
   */
  def loadData(sc: SparkContext): DataFrame = {
    // Create a sql context: the SQLContext wraps the SparkContext, and is specific to Spark SQL.
    // It is the entry point in Spark SQL.
    // TODO write code here
    val sqlcontext = null

    // Load the data regarding the file is a json file
    // Hint: use the sqlContext and apply the read method before loading the json file
    // TODO write code here
    ???
  }


  /**
   *  See how looks the dataframe
   */
  def showDataFrame(sc: SparkContext) = {
    val dataframe = loadData(sc)

    // Displays the content of the DataFrame to stdout
    // TODO write code here
    ???
  }

  /**
   * Print the schema
   */
  def printSchema(sc: SparkContext) = {
    val dataframe = loadData(sc)

    // Print the schema
    // TODO write code here
    ???
  }

  /**
   * Find people who are located in Paris
   */
  def filterByLocation(sc: SparkContext): DataFrame = {
    val dataframe = loadData(sc)

    // Select all the persons which are located in Paris
    // TODO write code here
    ???
  }


  /**
   *  Find the user who tweets the more
   */
  def mostPopularTwitterer(sc: SparkContext): (Long, String) = {
    val dataframe = loadData(sc)

    // First group the tweets by user
    // Then sort by descending order and take the first one
    // TODO write code here
    ???
  }

}
